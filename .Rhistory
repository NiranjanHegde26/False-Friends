t.test(USAccDeaths[1:12], USAccDeaths[61:72], alternative="greater")
source('C:/Users/Niranjan/Downloads/Sheet02.r', echo=TRUE)
# Load necessary library
library(ggplot2)
# Generate values for x-axis
x <- seq(-4, 4, by = 0.01)
# Probability Density Function (PDF)
pdf <- dnorm(x, mean = 0, sd = 1)
# Cumulative Distribution Function (CDF)
cdf <- pnorm(x, mean = 0, sd = 1)
# Quantile Function (Inverse CDF)
qf <- qnorm(cdf, mean = 0, sd = 1)
# Create a data frame for plotting
df <- data.frame(x = x, pdf = pdf, cdf = cdf, qf = qf)
# Plotting
ggplot(df, aes(x)) +
# PDF
geom_line(aes(y = pdf, color = "PDF"), size = 1) +
# CDF
geom_line(aes(y = cdf, color = "CDF"), size = 1) +
# Quantile function
geom_line(aes(y = x, x = qf, color = "Quantile Function"), size = 1) +
# Labels and theme
labs(title = "Standard Normal Distribution (μ = 0, σ = 1)",
x = "x", y = "Density / Probability",
color = "Function") +
scale_color_manual(values = c("PDF" = "blue", "CDF" = "red", "Quantile Function" = "green")) +
theme_minimal()
# Install and load necessary packages if not already installed
if (!requireNamespace("ggplot2", quietly = TRUE)) {
install.packages("ggplot2")
}
library(ggplot2)
# Example data
cycles <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
sum_of_squares_error <- c(0.000120, 0.416655, 0.000037, 0.043660, 0.279191, 0.000000, 0.000001, 0.004399, 0.265914)
annotations <- c(‘a’, ‘d’, ‘i’, ‘i’, ‘g’, ‘u’, ‘u’, ‘u’, ‘u’, ‘b’)
# Create data frame
df <- data.frame(cycles = cycles, sum_of_squares_error = sum_of_squares_error, annotations = annotations)
# Create the plot
ggplot(data = df, aes(x = cycles, y = sum_of_squares_error)) +
geom_line() +  # Add line plot
geom_point() +  # Add points
geom_text(aes(label = annotations), vjust = -0.5) +  # Add custom annotations
labs(x = "Cycles", y = "Sum of Squares Error", title = "Sum of Squares Error vs. Cycles with Custom Annotations") +  # Add axis labels and title
ylim(0, 0.6) +  # Set y-axis limit
theme_minimal() +  # Set theme
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())  # Remove grid lines
library(ggplot2)
# Example data
cycles <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
sum_of_squares_error <- c(0.000120, 0.416655, 0.000037, 0.043660, 0.279191, 0.000000, 0.000001, 0.004399, 0.265914)
annotations <- c(‘a’, ‘d’, ‘i’, ‘i’, ‘g’, ‘u’, ‘u’, ‘u’, ‘u’, ‘b’)
library(ggplot2)
# Example data
cycles <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
sum_of_squares_error <- c(0.000120, 0.416655, 0.000037, 0.043660, 0.279191, 0.000000, 0.000001, 0.004399, 0.265914)
annotations <- c("a", "d", "i", "i", "g", "u", "u", "u", "u", "b")
# Create data frame
df <- data.frame(cycles = cycles, sum_of_squares_error = sum_of_squares_error, annotations = annotations)
# Create the plot
ggplot(data = df, aes(x = cycles, y = sum_of_squares_error)) +
geom_line() +  # Add line plot
geom_point() +  # Add points
geom_text(aes(label = annotations), vjust = -0.5) +  # Add custom annotations
labs(x = "Cycles", y = "Sum of Squares Error", title = "Sum of Squares Error vs. Cycles with Custom Annotations") +  # Add axis labels and title
ylim(0, 0.6) +  # Set y-axis limit
theme_minimal() +  # Set theme
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())  # Remove grid lines
library(ggplot2)
# Example data
cycles <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)
sum_of_squares_error <- c(0.000120, 0.416655, 0.000037, 0.043660, 0.279191, 0.000000, 0.000001, 0.004399, 0.265914)
annotations <- c("a", "d", "i", "i", "g", "u", "u", "u", "u", "b")
# Create data frame
df <- data.frame(cycles = cycles, sum_of_squares_error = sum_of_squares_error, annotations = annotations)
# Create the plot
ggplot(data = df, aes(x = cycles, y = sum_of_squares_error)) +
geom_line() +  # Add line plot
geom_point() +  # Add points
geom_text(aes(label = annotations), vjust = -0.5) +  # Add custom annotations
labs(x = "Cycles", y = "Sum of Squares Error", title = "Sum of Squares Error vs. Cycles with Custom Annotations") +  # Add axis labels and title
ylim(0, 0.6) +  # Set y-axis limit
theme_minimal() +  # Set theme
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())  # Remove grid lines
df <- data.frame(cycles = cycles, sum_of_squares_error = sum_of_squares_error, annotations = annotations)
print(df)
library(ggplot2)
# Example data
cycles <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)
sum_of_squares_error <- c(0.000120, 0.416655, 0.000037, 0.043660, 0.279191, 0.000000, 0.000001, 0.004399, 0.265914)
annotations <- c("a", "d", "i", "i", "g", "u", "u", "u", "b")
# Create data frame
df <- data.frame(cycles = cycles, sum_of_squares_error = sum_of_squares_error, annotations = annotations)
print(df)
# Create the plot
ggplot(data = df, aes(x = cycles, y = sum_of_squares_error)) +
geom_line() +  # Add line plot
geom_point() +  # Add points
geom_text(aes(label = annotations), vjust = -0.5) +  # Add custom annotations
labs(x = "Cycles", y = "Sum of Squares Error", title = "Sum of Squares Error vs. Cycles with Custom Annotations") +  # Add axis labels and title
ylim(0, 0.6) +  # Set y-axis limit
theme_minimal() +  # Set theme
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())  # Remove grid lines
library(ggplot2)
# Example data
cycles <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)
sum_of_squares_error <- c(0.000120, 0.416655, 0.000037, 0.043660, 0.279191, 0.000000, 0.000001, 0.004399, 0.265914)
annotations <- c("a", "d", "i", "i", "g", "u", "u", "u", "b")
# Create data frame
df <- data.frame(cycles = cycles, sum_of_squares_error = sum_of_squares_error, annotations = annotations)
print(df)
# Create the plot
ggplot(data = df, aes(x = cycles, y = sum_of_squares_error)) +
geom_line() +  # Add line plot
geom_point() +  # Add points
geom_text(aes(label = annotations), vjust = -0.5) +  # Add custom annotations
scale_x_continuous(breaks = cycles) +
labs(x = "Cycles", y = "Sum of Squares Error", title = "Sum of Squares Error vs. Cycles with Custom Annotations") +  # Add axis labels and title
ylim(0, 0.6) +  # Set y-axis limit
theme_minimal() +  # Set theme
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())  # Remove grid lines
library(ggplot2)
# Example data
cycles <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)
sum_of_squares_error <- c(0.000120, 0.416655, 0.000037, 0.043660, 0.279191, 0.000000, 0.000001, 0.004399, 0.265914)
annotations <- c("a", "d", "i", "i", "g", "u", "u", "u", "b")
# Create data frame
df <- data.frame(cycles = cycles, sum_of_squares_error = sum_of_squares_error, annotations = annotations)
print(df)
# Create the plot
ggplot(data = df, aes(x = cycles, y = sum_of_squares_error)) +
geom_line() +  # Add line plot
geom_point() +  # Add points
geom_text(aes(label = annotations), vjust = -0.5) +  # Add custom annotations
scale_x_continuous(breaks = cycles) +
labs(x = "Cycles", y = "Sum of Squares Error", title = "Sum of Squares Error vs. Cycles with Custom Annotations") +  # Add axis labels and title
ylim(0, 0.6) +  # Set y-axis limit
theme_minimal() +  # Set theme
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())  # Remove grid lines
library(ggplot2)
# Example data
cycles <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)
sum_of_squares_error <- c(0.000120, 0.416655, 0.000037, 0.043660, 0.279191, 0.000000, 0.000001, 0.004399, 0.265914)
annotations <- c("a", "d", "i", "i", "g", "u", "u", "u", "b")
#
df <- data.frame(cycles = cycles,
sum_of_squares_error = sum_of_squares_error,
annotations = annotations)
# Create the plot
ggplot(data = df, aes(x = cycles, y = sum_of_squares_error)) +
geom_line() +  # Add line plot
geom_point() +  # Add points
geom_text(aes(label = annotations), vjust = -0.5) +  # Add custom annotations
labs(x = "Cycles", y = "Sum of Squares Error", title = "Sum of Squares Error vs. Cycles with Custom Annotations") +  # Add axis labels and title
scale_x_continuous(breaks = cycles) +  # Ensure x-axis shows integer cycles
ylim(0, 0.6) +  # Set y-axis limit
theme_minimal() +  # Set theme
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
library(ggplot2)
# Example data
cycles <- c(1, 2, 3, 4, 5, 6, 7, 8, 9)
sum_of_squares_error <- c(0.000120, 0.416655, 0.000037, 0.043660, 0.279191, 0.000000, 0.000001, 0.004399, 0.265914)
annotations <- c("a", "d", "i", "i", "g", "u", "u", "u", "b")
#
df <- data.frame(cycles = cycles,
sum_of_squares_error = sum_of_squares_error,
annotations = annotations)
# Create the plot
ggplot(data = df, aes(x = cycles, y = sum_of_squares_error)) +
geom_line() +  # Add line plot
geom_point() +  # Add points
geom_text(aes(label = annotations), vjust = -0.5) +  # Add custom annotations
labs(x = "Cycles", y = "Sum of Squares Error", title = "Sum of Squares Error vs. Cycles with Custom Annotations") +  # Add axis labels and title
scale_x_continuous(breaks = cycles) +  # Ensure x-axis shows integer cycles
ylim(0, 0.5) +  # Set y-axis limit
theme_minimal() +  # Set theme
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
setwd("D:/Studies/2nd Semester/Experimental methods for Psycholinguistic Research/Project/False-Friends")
library(dplyr)
library(tidyr)
stimuli_data <- read.csv("main_output.csv")
demographics_data <- read.csv("demographics_output.csv")
vst_data <- read.csv("vst_output.csv")
proficiency_df <- data.frame(
ParticipantId = demographics_data$ParticipantId,
Proficiency = demographics_data$L1_level
)
mean_reading_time_self_reported_proficiency <-stimuli_data %>%
left_join(proficiency_df, by = "ParticipantId")
nrow(mean_reading_time_self_reported_proficiency)
mean_reading_time_self_reported_proficiency$Item <-1:nrow(mean_reading_time_self_reported_proficiency)
mean_reading_time_self_reported_proficiency$Proficiency <-  factor(mean_reading_time_self_reported_proficiency$Proficiency, levels = c("intermediate", "advanced"))
contrasts(mean_reading_time_self_reported_proficiency$Proficiency) <- contr.helmert(2)
mean_reading_time_self_reported_proficiency$Type <- factor(mean_reading_time_self_reported_proficiency$Type, levels = c("false friend", "cognate", "unrelated"))
word_type_contrasts <- matrix(c(
2/3, -1/3, -1/3,
0, 1/2, -1/2
), ncol = 2)
contrasts(mean_reading_time_self_reported_proficiency$Type) <- word_type_contrasts
library(lme4)
install.packages("lme4", type = "source")
library(lme4)
mean_reading_time_self_reported_proficiency$Item <- 1:nrow(mean_reading_time_self_reported_proficiency)
model <- lmer(Reading.time ~ Proficiency * Type + (1|ParticipantId) + (1|Item), data = mean_reading_time_self_reported_proficiency)
source("D:/Studies/2nd Semester/Experimental methods for Psycholinguistic Research/Project/False-Friends/analysis2..r", echo=TRUE)
install.packages("lme4", type = "source")
source("D:/Studies/2nd Semester/Experimental methods for Psycholinguistic Research/Project/False-Friends/analysis2..r", echo=TRUE)
install.packages("lme4", type = "source")
source("D:/Studies/2nd Semester/Experimental methods for Psycholinguistic Research/Project/False-Friends/analysis2..r", echo=TRUE)
install.packages("lme4", type = "source")
source("D:/Studies/2nd Semester/Experimental methods for Psycholinguistic Research/Project/False-Friends/analysis2..r", echo=TRUE)
install.packages("lme4", type = "source")
source("D:/Studies/2nd Semester/Experimental methods for Psycholinguistic Research/Project/False-Friends/analysis2..r", echo=TRUE)
install.packages("lme4", type = "source")
source("D:/Studies/2nd Semester/Experimental methods for Psycholinguistic Research/Project/False-Friends/analysis2..r", echo=TRUE)
install.packages("lme4", type = "source")
source("D:/Studies/2nd Semester/Experimental methods for Psycholinguistic Research/Project/False-Friends/analysis2..r", echo=TRUE)
install.packages("lme4", type = "source")
participant_score <- vst_data %>%
group_by(ParticipantId) %>%
summarize(
Score = sum(Matches, na.rm = TRUE),
Accuracy = mean(Matches, na.rm = TRUE),
Total_Samples = n()
) %>%
ungroup()
nrow(mean_reading_time)
participant_score <- vst_data %>%
group_by(ParticipantId) %>%
summarize(
Score = sum(Matches, na.rm = TRUE),
Accuracy = mean(Matches, na.rm = TRUE),
Total_Samples = n()
) %>%
ungroup()
reading_time_participant_vst_score <- stimuli_data %>%
left_join(participant_score, by = "ParticipantId")
reading_time_participant_vst_score$Proficiency_Centered <-
scale(reading_time_participant_vst_score$Accuracy, center = TRUE, scale = FALSE)
reading_time_participant_vst_score <- stimuli_data %>%
left_join(participant_score, by = "ParticipantId")
reading_time_participant_vst_score$Proficiency_Centered <-
scale(reading_time_participant_vst_score$Accuracy, center = TRUE, scale = FALSE)
reading_time_participant_vst_score$Type <- factor(reading_time_participant_vst_score$Type,
levels = c("false friend", "cognate", "unrelated"))
word_type_contrasts <- matrix(c(
2/3, -1/3, -1/3,
0, 1/2, -1/2
), ncol = 2)
contrasts(reading_time_participant_vst_score$Type) <- word_type_contrasts
model <- lmer(Readin.time ~ Proficiency_Centered * Type + (1|ParticipantId),
data = reading_time_participant_vst_score,
REML = FALSE)
model <- lmer(Reading.time ~ Proficiency_Centered * Type + (1|ParticipantId),
data = reading_time_participant_vst_score,
REML = FALSE)
summary(model)
reading_time_participant_vst_score <- stimuli_data %>%
left_join(participant_score, by = "ParticipantId")
reading_time_participant_vst_score$Proficiency_Centered <-
scale(reading_time_participant_vst_score$Score, center = TRUE, scale = FALSE)
reading_time_participant_vst_score$Type <- factor(reading_time_participant_vst_score$Type,
levels = c("false friend", "cognate", "unrelated"))
word_type_contrasts <- matrix(c(
2/3, -1/3, -1/3,
0, 1/2, -1/2
), ncol = 2)
contrasts(reading_time_participant_vst_score$Type) <- word_type_contrasts
library(lmerTest)
reading_time_participant_vst_score <- stimuli_data %>%
left_join(participant_score, by = "ParticipantId")
reading_time_participant_vst_score$Proficiency_Centered <-
scale(reading_time_participant_vst_score$Score, center = TRUE, scale = FALSE)
reading_time_participant_vst_score$Type <- factor(reading_time_participant_vst_score$Type,
levels = c("false friend", "cognate", "unrelated"))
word_type_contrasts <- matrix(c(
2/3, -1/3, -1/3,
0, 1/2, -1/2
), ncol = 2)
contrasts(reading_time_participant_vst_score$Type) <- word_type_contrasts
library(lmerTest)
reading_time_participant_vst_score <- stimuli_data %>%
left_join(participant_score, by = "ParticipantId")
reading_time_participant_vst_score$Proficiency_Centered <-
scale(reading_time_participant_vst_score$Score, center = TRUE, scale = FALSE)
reading_time_participant_vst_score$Type <- factor(reading_time_participant_vst_score$Type,
levels = c("false friend", "cognate", "unrelated"))
word_type_contrasts <- matrix(c(
2/3, -1/3, -1/3,
0, 1/2, -1/2
), ncol = 2)
contrasts(reading_time_participant_vst_score$Type) <- word_type_contrasts
model <- lmer(Reading.time ~ Proficiency_Centered * Type + (1|ParticipantId),
data = reading_time_participant_vst_score,
REML = FALSE)
summary(model)
model <- lmer(Reading.time ~ Score * Type + (1|ParticipantId),
data = reading_time_participant_vst_score,
REML = FALSE)
summary(model)
source("D:/Studies/2nd Semester/Experimental methods for Psycholinguistic Research/Project/False-Friends/analysis2..r", echo=TRUE)
model1 <- lmer(Reading.time ~ Score * Type + (1|ParticipantId),
data = reading_time_participant_vst_score,
REML = FALSE)
summary(model1)
# Assuming 'Proficiency' is a factor with levels like "Low", "Medium", "High"
contrasts(mean_reading_time_self_reported_proficiency$Proficiency) <- contr.sum(levels(mean_reading_time_self_reported_proficiency$Proficiency))
# Fit the logistic mixed-effects model
model2 <- glmer(Matches ~ Proficiency * Type + (1 | ParticipantId),
data = mean_reading_time_self_reported_proficiency,
family = binomial)
proficiency_df <- data.frame(
ParticipantId = demographics_data$ParticipantId,
Proficiency = demographics_data$L1_level
)
mean_reading_time_self_reported_proficiency <-stimuli_data %>%
left_join(proficiency_df, by = "ParticipantId")
nrow(mean_reading_time_self_reported_proficiency)
contrasts(mean_reading_time_self_reported_proficiency$Proficiency) <- contr.sum(levels(mean_reading_time_self_reported_proficiency$Proficiency))
mean_reading_time_self_reported_proficiency
levels(mean_reading_time_self_reported_proficiency$Proficiency)
contrasts(mean_reading_time_self_reported_proficiency$Proficiency) <- contr.sum(levels(as.factor(mean_reading_time_self_reported_proficiency$Proficiency)))
mean_reading_time_self_reported_proficiency$Proficiency <- as.factor(mean_reading_time_self_reported_proficiency$Proficiency)
contrasts(mean_reading_time_self_reported_proficiency$Proficiency) <- contr.sum(levels(mean_reading_time_self_reported_proficiency$Proficiency))
levels(mean_reading_time_self_reported_proficiency$Proficiency)
model2 <- glmer(Matches ~ Proficiency * Type + (1 | ParticipantId),
data = mean_reading_time_self_reported_proficiency,
family = binomial)
install.packages("lme4", type = "source")
library(lme4)
install.packages("lme4", type = "source")
remove.packages("Matrix")
remove.packages("lme4")
install.packages("lme4", type = "source")
library(lme4)
library(dplyr)
library(tidyr)
stimuli_data <- read.csv("main_output.csv")
demographics_data <- read.csv("demographics_output.csv")
vst_data <- read.csv("vst_output.csv")
proficiency_df <- data.frame(
ParticipantId = demographics_data$ParticipantId,
Proficiency = demographics_data$L1_level
)
mean_reading_time_self_reported_proficiency <-stimuli_data %>%
left_join(proficiency_df, by = "ParticipantId")
mean_reading_time_self_reported_proficiency$Proficiency <- as.factor(mean_reading_time_self_reported_proficiency$Proficiency)
contrasts(mean_reading_time_self_reported_proficiency$Proficiency) <- contr.sum(levels(mean_reading_time_self_reported_proficiency$Proficiency))
model2 <- glmer(Matches ~ Proficiency * Type + (1 | ParticipantId),
data = mean_reading_time_self_reported_proficiency,
family = binomial)
library(lme4)
model2 <- glmer(Matches ~ Proficiency * Type + (1 | ParticipantId),
data = mean_reading_time_self_reported_proficiency,
family = binomial)
summary(model2)
word_type_contrasts <- matrix(c(
2/3, -1/3, -1/3,
0, 1/2, -1/2
), ncol = 2)
contrasts(mean_reading_time_self_reported_proficiency$Type) <- word_type_contrasts
mean_reading_time_self_reported_proficiency$Type <- as.factor(mean_reading_time_self_reported_proficiency$Type)
word_type_contrasts <- matrix(c(
2/3, -1/3, -1/3,
0, 1/2, -1/2
), ncol = 2)
contrasts(mean_reading_time_self_reported_proficiency$Type) <- word_type_contrasts
# Fit the logistic mixed-effects model
model2 <- glmer(Matches ~ Proficiency * Type + (1 | ParticipantId),
data = mean_reading_time_self_reported_proficiency,
family = binomial)
summary(model2)
vst_data <- read.csv("vst_output.csv")
participant_score <- vst_data %>%
group_by(ParticipantId) %>%
summarize(
Score = sum(Matches, na.rm = TRUE),
Accuracy = mean(Matches, na.rm = TRUE),
Total_Samples = n()
) %>%
ungroup()
reading_time_participant_vst_score <- stimuli_data %>%
left_join(participant_score, by = "ParticipantId")
reading_time_participant_vst_score$Proficiency_Centered <-
scale(reading_time_participant_vst_score$Score, center = TRUE, scale = FALSE)
reading_time_participant_vst_score$Type <- factor(reading_time_participant_vst_score$Type,
levels = c("false friend", "cognate", "unrelated"))
word_type_contrasts <- matrix(c(
2/3, -1/3, -1/3,
0, 1/2, -1/2
), ncol = 2)
contrasts(reading_time_participant_vst_score$Type) <- word_type_contrasts
mean_reading_time_self_reported_proficiency$Type
model4 <- glmer(Matches ~ Score * Type + (1 | ParticipantId),
data = reading_time_participant_vst_score,
family = binomial)
summary(model4)
